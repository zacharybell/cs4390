{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment requires the classification of preposition attachment to nouns or verbs. The training set contains <b>20801</b> samples with binary labels of <b>N</b> or <b>V</b>. The testing data is fairly even in composition with <b>10865</b> noun attachments and <b>9936</b> verb attachments. A successful classifier would need to perform above <b>0.522</b> accuracy to beat a majority class prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach to this classification problem is to analyze the data to gain some insight about the feature. Then I will implement a classifier using binary regression to make predictions based on the features. This classifier could act as a good baseline for future classification experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>join</td>\n",
       "      <td>board</td>\n",
       "      <td>as</td>\n",
       "      <td>director</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>chairman</td>\n",
       "      <td>of</td>\n",
       "      <td>N.V.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>named</td>\n",
       "      <td>director</td>\n",
       "      <td>of</td>\n",
       "      <td>conglomerate</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>caused</td>\n",
       "      <td>percentage</td>\n",
       "      <td>of</td>\n",
       "      <td>deaths</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>using</td>\n",
       "      <td>crocidolite</td>\n",
       "      <td>in</td>\n",
       "      <td>filters</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      w0           w1  w2            w3      y\n",
       "0    0    join        board  as      director  False\n",
       "1    1      is     chairman  of          N.V.   True\n",
       "2    2   named     director  of  conglomerate   True\n",
       "3    3  caused   percentage  of        deaths   True\n",
       "4    5   using  crocidolite  in       filters  False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_ROOT   = 'data/PPAttachData'\n",
    "TRAINING    = 'training'\n",
    "TESTING     = 'test'\n",
    "VALIDATION  = 'devset'\n",
    "\n",
    "training_df   = pd.read_csv(os.path.join(DATA_ROOT, TRAINING), \n",
    "                            delimiter=' ', \n",
    "                            header=None,\n",
    "                            names=['idx', 'w0', 'w1', 'w2', 'w3', 'y'],\n",
    "                            converters = {'y': lambda label : label == 'N'})\n",
    "\n",
    "testing_df    = pd.read_csv(os.path.join(DATA_ROOT, TESTING), \n",
    "                            delimiter=' ', \n",
    "                            header=None,\n",
    "                            names=['idx', 'w0', 'w1', 'w2', 'w3', 'y'],\n",
    "                            converters = {'y': lambda label : label == 'N'})\n",
    "\n",
    "validation_df = pd.read_csv(os.path.join(DATA_ROOT, VALIDATION), \n",
    "                            delimiter=' ', \n",
    "                            header=None,\n",
    "                            names=['idx', 'w0', 'w1', 'w2', 'w3', 'y'],\n",
    "                            converters = {'y': lambda label : label == 'N'})\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:    0.5223306571799433\n",
      "Testing:     0.589602841459477\n",
      "Validation:  0.5303292894280762\n"
     ]
    }
   ],
   "source": [
    "print('Training:   ', np.sum(training_df['y']==True) / len(training_df))\n",
    "print('Testing:    ', np.sum(testing_df['y']==True) / len(testing_df))\n",
    "print('Validation: ', np.sum(validation_df['y']==True) / len(validation_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing set is more imbalanced than the other two which could be a very realistic problem depending on the scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done so that K-fold can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.concat([training_df, validation_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Word Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought it would be good to look at number of unique words for each column for some insight into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique verbs       :  3496\n",
      "Unique nouns (w1)  :  4791\n",
      "Unique prepositions:  69\n",
      "Unique nouns (w3)  :  6054\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique verbs       : \", training_df['w0'].str.lower().nunique())\n",
    "print(\"Unique nouns (w1)  : \", training_df['w1'].str.lower().nunique())\n",
    "print(\"Unique prepositions: \", training_df['w2'].str.lower().nunique())\n",
    "print(\"Unique nouns (w3)  : \", training_df['w3'].str.lower().nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the small feature space of the prepositions (in comparison) I thought it would be interesting to see how a classifier would perform on just this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7190829835324507"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "training_prep = training_df['w2'].str.lower()\n",
    "testing_prep  = testing_df['w2'].str.lower()\n",
    "\n",
    "enc = LabelBinarizer().fit(pd.concat([training_prep, testing_prep]))\n",
    "\n",
    "training_prep_oh = enc.transform(training_prep)\n",
    "testing_prep_oh  = enc.transform(testing_prep)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# 5-fold cross validation\n",
    "model = LogisticRegressionCV(cv=5, random_state=0)\n",
    "\n",
    "print(\"Accuracy on Test Data\")\n",
    "model.fit(training_prep_oh, training_df['y']).score(testing_prep_oh, testing_df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear from the 0.719 accuracy (p < 0.000001) that using the preposition itself is a signficant feature for general classification. My intuition is that the trailing noun might offer more information for an improved classifier. Future work could be done to extract more features and use more complex models that handle these features in an optimal way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Myself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
