{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to study the interactions between football fans and internet trolls as a domain. The observed domain is rather simple to model. Football fans are very passionate about their team(s) and want to argue with just about anyone who disagrees with them. Because of this my theory is that they would be susceptible to interacting with a chatbot unwittingly. The exchange is also very predictable as general insults appear to work fairly well for continuing debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design for the chatbot is rather simple. I've collected a sample of approximately 50 real arguements between \"assumed\" interenet trolls and Colts fans. Each sample is a pair of posts and response, as well as a list of context words that have been annotated to describe the interaction. In order to interact with the bot the user submits a string as input and the algorithm matches each word in that input against all context words in each sample and produces an output from the highest scoring sample. The scoring function takes the total matches over the total amount of words in the input string. The exchange is initiate by the chatbot selecting at random an offensive comment against the football team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the major weaknesses I noted with the model deal with a lack of robustness for any exchange outside of context. Unless I submitted a string that insulted the bot or defended the football team, the bot would fail to produce an adequate response. Another deficiency I noted was that some responses had way too much context. I attempted to solve this problem by adding more context words to the more specific interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested my model by having a football fan interact with the chatbot. They were aware of the bot's likely behavior before the interaction. I was tempted to have unwitting football fan interaction but decided against it for ethical reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_rebuttal(response, data, default_response=\"learn the game\"):\n",
    "    response = list(filter(str.isalpha, map(str.lower, response.split())))\n",
    "\n",
    "    best_idx = -1\n",
    "    best_score = -1\n",
    "    for i, interaction in enumerate(data):\n",
    "        matches = 0\n",
    "        score = 0\n",
    "        for w in interaction['context']:\n",
    "            matches += response.count(w)\n",
    "        score = matches / (len(response) + 1)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_idx = i\n",
    "    if best_idx >= 0:\n",
    "        return data[best_idx]['response']\n",
    "    else:\n",
    "        return default_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bench Luck\n"
     ]
    }
   ],
   "source": [
    "with open('./posts.json') as f:\n",
    "    initial_posts = json.load(f)\n",
    "    print(random.choice(initial_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fan response: bench yourself\n",
      "Troll response:  because (the bust)hasn't developed\n",
      "Fan response: luck is the best qb\n",
      "Troll response:  Brissett, he's better than (the bust)\n",
      "Fan response: luck is better than brissett though\n",
      "Troll response:  how many rings?and if u think having more sacks than TD'S is exceptable please leave my comment\n",
      "Fan response: Brissett doesn't have any rings\n",
      "Troll response:  because (the bust)hasn't developed\n",
      "Fan response: luck has better stats\n",
      "Troll response:  dummy\n",
      "Fan response: loser\n",
      "Troll response:  u lost at birth,lololol just look at u\n",
      "Fan response: you're mean\n",
      "Troll response:  because (the bust)hasn't developed\n",
      "Fan response: yeah he has\n",
      "Troll response:  because (the bust)hasn't developed\n",
      "Fan response: you already said that\n",
      "Troll response:  because (the bust)hasn't developed\n"
     ]
    }
   ],
   "source": [
    "with open('./responses.json') as f:\n",
    "    data = json.load(f)\n",
    "    while(True):\n",
    "        response = input('Fan response: ')\n",
    "        print(\"Troll response: \", nearest_rebuttal(response, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model would definetly benefit from some refinement in the future. It appears to give accurate responses sometimes and other times seems to be completely out of context. Fortunately, given the nature of online trolling repeated out of context responses are pretty normal, but given any other situation this behavior would cause problems. The model would definetly benefit from a much greater set of interactions to pull. The biggest improvements could be made by better isolating the context of the input and selecting the appropriate response. Future work could also prevent repetitive responses by creating probability distributions from the scoring function to create randomness in responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
